import os
import pandas as pd
import glob
import re


def check_column_contains(file_path, words):
    """
    Checks if any column name in the given CSV file contains any of the specified words/patterns 
    and prints their values.

    Parameters:
    file_path (str): Path to the CSV file.
    words (list of str): List of words or patterns to check for in the column names.

    Returns:
    None (prints results)
    """
    # Load the dataset
    df = pd.read_csv(file_path, dtype=str, low_memory=False)
    
    # Standardize column names (lowercase & strip spaces)
    df.columns = df.columns.str.lower().str.strip()

    # Check if any column name contains any of the specified words
    matching_columns = [col for col in df.columns if any(word.lower() in col for word in words)]
    
    if matching_columns:
        print(f"\nâœ… Columns in {file_path} that contain any of the words {', '.join(words)}:")
        for col in matching_columns:
            print(f"  - {col}:")
            non_nan_values = df[col].dropna()
            if not non_nan_values.empty:
                print(non_nan_values.head()) # Print the first few values of the column
            else:
                print("No non nan values in this col")
    else:
        print(f"âŒ No columns in {file_path} contain any of the specified words: {', '.join(words)}.")


def find_misplaced_columns(desktop_path, start_year=2017, end_year=2024, check_specific_year=None):
    """
    Checks yearly_data_YYYY.csv files to find:
    1. Columns that do NOT contain the expected year in their names.
    2. If a specific year is provided, finds columns that contain multiple years in their names.

    Parameters:
    desktop_path (str): Path to the desktop where the yearly files are stored.
    start_year (int): Start of the year range to check.
    end_year (int): End of the year range to check.
    check_specific_year (int, optional): If provided, checks which columns contain multiple years.

    Returns:
    None (prints results)
    """
    years_to_check = [str(year) for year in range(2017, 2025)]

    for year in range(start_year, end_year + 1):
        file_path = os.path.join(desktop_path, f"yearly_data_{year}.csv")

        if not os.path.exists(file_path):
            print(f"âŒ File not found: {file_path}")
            continue

        # Load dataset with low_memory=False to prevent dtype warnings
        df = pd.read_csv(file_path, dtype=str, low_memory=False)
        
        # Standardize column names (lowercase & strip spaces)
        df.columns = df.columns.str.lower().str.strip()

        # Find columns that do NOT contain the expected year
        misplaced_columns = [col for col in df.columns if str(year) not in col]

        # Print misplaced columns
        if misplaced_columns:
            print(f"\nâš ï¸ Columns in yearly_data_{year}.csv that do NOT contain '{year}':")
            print(misplaced_columns)
        else:
            print(f"âœ… All columns in yearly_data_{year}.csv correctly contain '{year}'.")

        # If a specific year is provided, find columns with multiple years
        if check_specific_year and check_specific_year == year:
            multiple_year_columns = [col for col in df.columns if sum(y in col for y in years_to_check) > 1]
            
            if multiple_year_columns:
                print(f"\nğŸ” Columns in yearly_data_{year}.csv that contain multiple years:")
                for col in multiple_year_columns:
                    found_years = [y for y in years_to_check if y in col]
                    print(f"  - {col} (Years Found: {', '.join(found_years)})")
            else:
                print(f"âœ… No columns in yearly_data_{year}.csv contain multiple years.")

# Example Usage
desktop_path = os.path.expanduser("~/Desktop")
#find_misplaced_columns(desktop_path, check_specific_year=2023)  # Change 2019 to the year you want to check

file_path = os.path.join(desktop_path, "yearly_data_2023.csv")
check_column_contains(file_path, ["district 2023 domain"])
