{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive District Data Scraper\n",
    "This scraper allows users to select the level and type of data they would like to download from the TAPR Advanced Data Download on the TEA website. If the level is \"D\" for District, district type data will also be downloaded in addition to the TAPR data unless the user has indicated they do not want the data (set dist_type = False). \n",
    "\n",
    "If the files already exist, the scraper will not download new files. \n",
    "\n",
    "\n",
    "The scraper creates separate folders for each year of data and names the files with the appropriate year. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### District Type Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def district_type_scraper(year):\n",
    "   school_year = str(year-1)+\"-\"+str(year-2000)\n",
    "   url = f'https://tea.texas.gov/reports-and-data/school-data/district-type-data-search/district-type-{school_year}'\n",
    "   grab = requests.get(url)\n",
    "   soup = BeautifulSoup(grab.text, 'html.parser')\n",
    "   xlsx = []\n",
    "   for link in soup.find_all(\"a\"):\n",
    "      data = str(link.get('href'))\n",
    "      if re.search(\".xlsx$\", data):\n",
    "         return pd.read_excel(f\"https://tea.texas.gov{data}\", sheet_name= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_downloads(variables, year, directory, timeout = 200):\n",
    "    start_time = time.time()\n",
    "    expected_files = []\n",
    "\n",
    "    for var in variables:\n",
    "\n",
    "        if year < 2021:\n",
    "            expected_files.append(f\"DIST{var}.dat\" if var != \"REF\" else \"DREF.dat\")\n",
    "        else:\n",
    "            expected_files.append(f\"DIST{var}.csv\" if var != \"REF\" else \"DREF.csv\")\n",
    "    check = 1\n",
    "    while time.time() - start_time < timeout:\n",
    "        downloaded_files = os.listdir(directory)\n",
    "        \n",
    "        if all(file in downloaded_files and not file.endswith(\".crdownload\") for file in expected_files):\n",
    "            print(f\"All downloads for {year} completed successfully.\")\n",
    "            print(\"\")\n",
    "            return True\n",
    "        if check == 1: \n",
    "            print(\"Waiting for all files to download...\")\n",
    "        check += 1\n",
    "        time.sleep(5)\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_renamer(directory, year, prefix, var, level):\n",
    "    for ext in ['.csv', '.dat']:\n",
    "        old_patterns = [\n",
    "               f\"{prefix}{var}{ext}\",\n",
    "               f\"{level}{var}{ext}\"  # Some files might not include the prefix\n",
    "                ]\n",
    "                        \n",
    "        for old_pattern in old_patterns:\n",
    "            old_name = os.path.join(directory, old_pattern)\n",
    "            if os.path.exists(old_name):\n",
    "                if var == \"REF\":\n",
    "                    new_name = os.path.join(directory, f\"{level}{var}_{year}{ext}\")\n",
    "                else: \n",
    "                    new_name = os.path.join(directory, f\"{prefix}{var}_{year}{ext}\")\n",
    "                os.rename(old_name, new_name)\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tea_scraper(years, variables, level, dist_type = True):\n",
    "    \"\"\"\n",
    "    Scrape all HERC data for specified years, variables, and level of data.\n",
    "    \n",
    "    Parameters:\n",
    "    years (list): List of years to scrape data for (formatted YYYY)\n",
    "    variables (list): List of variable codes to download (such as \"GRAD\")\n",
    "    level (str): Administrative level to scrape. Options:\n",
    "        'C' for Campus\n",
    "        'D' for District\n",
    "        'R' for Region\n",
    "        'S' for State\n",
    "    \"\"\"\n",
    "    directory_path_name = os.getcwd()\n",
    "    # Validation for level parameter\n",
    "    valid_levels = {\n",
    "        'C': 'Campus',\n",
    "        'D': 'District',\n",
    "        'R': 'Region',\n",
    "        'S': 'State'\n",
    "    }\n",
    "    \n",
    "    if level not in valid_levels:\n",
    "        raise ValueError(f\"Invalid level. Must be one of: {', '.join(valid_levels.keys())}\")\n",
    "    \n",
    "    # Create prefix for filenames based on level\n",
    "    file_prefix = {\n",
    "        'C': 'CAMP',\n",
    "        'D': 'DIST',\n",
    "        'R': 'REGN',\n",
    "        'S': 'STATE'\n",
    "    }[level]\n",
    "    \n",
    "    for year in years:\n",
    "        ### TAPR DATA DOWNLOAD ###\n",
    "        # Create full path for year directory\n",
    "        dir_name = f\"raw_data{year}\"\n",
    "        full_dir_path = os.path.join(directory_path_name, dir_name)\n",
    "        os.makedirs(full_dir_path, exist_ok=True)\n",
    "        \n",
    "        # Configure Chrome options\n",
    "        chrome_options = webdriver.ChromeOptions()\n",
    "        absolute_download_path = os.path.abspath(full_dir_path)\n",
    "        \n",
    "        # Add additional Chrome preferences to prevent download prompts\n",
    "        prefs = {\n",
    "            \"download.default_directory\": absolute_download_path,\n",
    "            \"download.prompt_for_download\": False,\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing.enabled\": True,\n",
    "            \"profile.default_content_settings.popups\": 0\n",
    "        }\n",
    "        chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "        \n",
    "        # Add additional Chrome arguments\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"--no-sandbox\")\n",
    "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        \n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "        driver.get(f\"https://rptsvr1.tea.texas.gov/perfreport/tapr/{year}/download/DownloadData.html\")\n",
    "        \n",
    "        # Select appropriate level\n",
    "        level_select = driver.find_element(By.XPATH, f\"//input[@type='radio' and @name='sumlev' and @value='{level}']\")\n",
    "        level_select.click()\n",
    "        \n",
    "        unavailable = []\n",
    "        print(f\"Downloading {valid_levels[level]} Level TAPR Data for {year}...\")\n",
    "        \n",
    "        for var in variables:\n",
    "            print(f\"Checking for {file_prefix}{var} data...\")\n",
    "            # Updated file patterns to include level prefix and year\n",
    "            file_patterns = [\n",
    "                f\"{file_prefix}{var}_{year}.csv\",\n",
    "                f\"{file_prefix}{var}_{year}.dat\",\n",
    "                f\"{level}{var}_{year}.dat\",  # Some files might not include the prefix\n",
    "                f\"{level}{var}_{year}.csv\"\n",
    "            ]\n",
    "            \n",
    "            if any(os.path.isfile(os.path.join(full_dir_path, file)) for file in file_patterns):\n",
    "                print(f\"{var}_{year} already exists\")\n",
    "                unavailable.append(var)\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                select_data = driver.find_element(By.XPATH, f\"//input[@type='radio' and @name='setpick' and @value='{var}']\")\n",
    "                select_data.click()\n",
    "                \n",
    "                # Add a small delay after clicking the radio button\n",
    "                time.sleep(1)\n",
    "                \n",
    "                download = driver.find_element(By.XPATH, \"//input[@type='submit' and @value='Continue']\")\n",
    "                download.click()\n",
    "                print(f\"Downloaded {level if var == 'REF' else file_prefix}{var} for {year}\")\n",
    "                \n",
    "            except NoSuchElementException:\n",
    "                print(f\"{var} not found for {year}\")\n",
    "                unavailable.append(var)\n",
    "                continue\n",
    "        \n",
    "        available_vars = set(variables) - set(unavailable)\n",
    "        # do not shut down driver until time-out occurs or all available files have finished downloading\n",
    "        if wait_for_downloads(variables = available_vars, year = year, directory = full_dir_path):\n",
    "            for a_var in available_vars:\n",
    "                file_renamer(directory = full_dir_path, year = year, prefix = file_prefix, var = a_var, level = level)  \n",
    "        driver.quit()\n",
    "\n",
    "        ### DISTRICT TYPE DATA DOWNLOAD ###\n",
    "        if level == \"D\" and dist_type:\n",
    "            print(f\"Downloading District Type Data for {year}...\")\n",
    "            \n",
    "            if os.path.isfile(os.path.join(full_dir_path, f\"district_type{year}.csv\")):\n",
    "                print(f\"District Type Data for {year} already exists\") # don't download if it already exists\n",
    "                print(\"\")\n",
    "                continue\n",
    "\n",
    "            df = district_type_scraper(year) # get the dataframe with the sheet data\n",
    "            df.to_csv(f\"{dir_name}/district_type{year}.csv\") # save it to the raw_data{year} folder\n",
    "\n",
    "            print(f\"Downloaded District Type Data for {year}\")\n",
    "            print(\"\")\n",
    "    print(\"All Data Downloaded!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading District Level TAPR Data for 2018...\n",
      "Checking for DISTPROF data...\n",
      "PROF_2018 already exists\n",
      "Checking for DISTPERF1 data...\n",
      "PERF1 not found for 2018\n",
      "Checking for DISTGRAD data...\n",
      "GRAD_2018 already exists\n",
      "Checking for DISTSTAAR1 data...\n",
      "STAAR1_2018 already exists\n",
      "Checking for DISTREF data...\n",
      "REF_2018 already exists\n",
      "Checking for DISTPERF data...\n",
      "PERF_2018 already exists\n",
      "All downloads for 2018 completed successfully.\n",
      "\n",
      "Downloading District Type Data for 2018...\n",
      "District Type Data for 2018 already exists\n",
      "\n",
      "Downloading District Level TAPR Data for 2019...\n",
      "Checking for DISTPROF data...\n",
      "PROF_2019 already exists\n",
      "Checking for DISTPERF1 data...\n",
      "PERF1 not found for 2019\n",
      "Checking for DISTGRAD data...\n",
      "GRAD_2019 already exists\n",
      "Checking for DISTSTAAR1 data...\n",
      "STAAR1_2019 already exists\n",
      "Checking for DISTREF data...\n",
      "REF_2019 already exists\n",
      "Checking for DISTPERF data...\n",
      "PERF_2019 already exists\n",
      "All downloads for 2019 completed successfully.\n",
      "\n",
      "Downloading District Type Data for 2019...\n",
      "District Type Data for 2019 already exists\n",
      "\n",
      "Downloading District Level TAPR Data for 2020...\n",
      "Checking for DISTPROF data...\n",
      "PROF_2020 already exists\n",
      "Checking for DISTPERF1 data...\n",
      "PERF1 not found for 2020\n",
      "Checking for DISTGRAD data...\n",
      "GRAD_2020 already exists\n",
      "Checking for DISTSTAAR1 data...\n",
      "STAAR1_2020 already exists\n",
      "Checking for DISTREF data...\n",
      "REF_2020 already exists\n",
      "Checking for DISTPERF data...\n",
      "PERF_2020 already exists\n",
      "All downloads for 2020 completed successfully.\n",
      "\n",
      "Downloading District Type Data for 2020...\n",
      "District Type Data for 2020 already exists\n",
      "\n",
      "Downloading District Level TAPR Data for 2021...\n",
      "Checking for DISTPROF data...\n",
      "PROF_2021 already exists\n",
      "Checking for DISTPERF1 data...\n",
      "PERF1_2021 already exists\n",
      "Checking for DISTGRAD data...\n",
      "GRAD_2021 already exists\n",
      "Checking for DISTSTAAR1 data...\n",
      "STAAR1_2021 already exists\n",
      "Checking for DISTREF data...\n",
      "REF_2021 already exists\n",
      "Checking for DISTPERF data...\n",
      "PERF not found for 2021\n",
      "All downloads for 2021 completed successfully.\n",
      "\n",
      "Downloading District Type Data for 2021...\n",
      "District Type Data for 2021 already exists\n",
      "\n",
      "Downloading District Level TAPR Data for 2022...\n",
      "Checking for DISTPROF data...\n",
      "PROF_2022 already exists\n",
      "Checking for DISTPERF1 data...\n",
      "PERF1_2022 already exists\n",
      "Checking for DISTGRAD data...\n",
      "GRAD_2022 already exists\n",
      "Checking for DISTSTAAR1 data...\n",
      "STAAR1_2022 already exists\n",
      "Checking for DISTREF data...\n",
      "REF_2022 already exists\n",
      "Checking for DISTPERF data...\n",
      "PERF not found for 2022\n",
      "All downloads for 2022 completed successfully.\n",
      "\n",
      "Downloading District Type Data for 2022...\n",
      "District Type Data for 2022 already exists\n",
      "\n",
      "Downloading District Level TAPR Data for 2023...\n",
      "Checking for DISTPROF data...\n",
      "PROF_2023 already exists\n",
      "Checking for DISTPERF1 data...\n",
      "PERF1_2023 already exists\n",
      "Checking for DISTGRAD data...\n",
      "GRAD_2023 already exists\n",
      "Checking for DISTSTAAR1 data...\n",
      "STAAR1_2023 already exists\n",
      "Checking for DISTREF data...\n",
      "REF_2023 already exists\n",
      "Checking for DISTPERF data...\n",
      "PERF not found for 2023\n",
      "All downloads for 2023 completed successfully.\n",
      "\n",
      "Downloading District Type Data for 2023...\n",
      "District Type Data for 2023 already exists\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the function with all currently available years and all the TAPR datasets\n",
    "tapr_2018_2023 = list(range(2018, 2024)) # all years with data that is currently available\n",
    "\n",
    "data_acronyms = ['PROF', 'PERF1', 'GRAD', 'STAAR1', 'REF', 'PERF'] # all the measures located on the TAPR website\n",
    "\n",
    "tea_scraper(years = tapr_2018_2023, variables = data_acronyms, level = \"D\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
