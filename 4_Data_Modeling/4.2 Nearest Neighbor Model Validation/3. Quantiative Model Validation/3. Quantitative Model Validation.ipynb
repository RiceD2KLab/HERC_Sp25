{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative analysis of what is the best distance metric. \n",
    "---  \n",
    "Methodology\n",
    "* 1 Curate 4 meaningful feature sets (Applicable combinations of features)\n",
    "* 2 Stratify the original dataset to pick 30 target districts to run nearest neighbor on (anchor districts)\n",
    "* 3 Find neighbors for combinations of anchor district, feature sets, and distance metrics (30*4*4=480)\n",
    "* 4 Examine variance of standardized columns (standardize all columns to get all on same scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary packages, lists, and functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = r\"C:\\Users\\mmath\\OneDrive\\Desktop\\Capstone\\HERC_Sp25\\4_Data_Modeling\\4.2 Nearest Neighbor Model Validation\\1. Nearest Neighbors Model\"\n",
    "os.chdir(current_directory)\n",
    "\n",
    "#Importing necessary packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "#Importing demogrpahic buckets \n",
    "from Demographic_Buckets import student_teacher_ratio\n",
    "from Demographic_Buckets import student_count\n",
    "from Demographic_Buckets import staff_count\n",
    "from Demographic_Buckets import race_ethnicity_percent\n",
    "from Demographic_Buckets import economically_disadvantaged\n",
    "from Demographic_Buckets import special_ed_504\n",
    "from Demographic_Buckets import language_education_percent\n",
    "from Demographic_Buckets import special_populations_percent\n",
    "from Demographic_Buckets import gifted_students\n",
    "from Demographic_Buckets import district_identifiers\n",
    "\n",
    "#Importing modeling functions \n",
    "from KNN_Model import calculate_missing_percentage\n",
    "from KNN_Model import drop_columns\n",
    "from KNN_Model import preprocess_data\n",
    "from KNN_Model import knn_distance\n",
    "from KNN_Model import knn_cosine\n",
    "from KNN_Model import knn_canberra\n",
    "from KNN_Model import find_nearest_districts\n",
    "from KNN_Model import get_neighbor_data\n",
    "\n",
    "#Importing diagnostic plot functions \n",
    "from KNN_Diagnostic_Plots import plot_texas_districts\n",
    "from KNN_Diagnostic_Plots import plot_race_ethnicity_stacked_bar\n",
    "from KNN_Diagnostic_Plots import plot_class_size_k6_bar\n",
    "from KNN_Diagnostic_Plots import plot_special_ed_504_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in Data & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the data\n",
    "df = pd.read_csv(r\"https://raw.githubusercontent.com/RiceD2KLab/HERC_Sp25/refs/heads/main/0_Datasets/1.0MergedData/merged_2023.csv\")\n",
    "\n",
    "df = df[df['Charter School (Y/N)'] == 'N']\n",
    "demographic_df = df[student_teacher_ratio + student_count + staff_count + race_ethnicity_percent + economically_disadvantaged +\n",
    "                    special_ed_504 + language_education_percent + special_populations_percent + gifted_students +\n",
    "                    district_identifiers]\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_cols = df.select_dtypes(include='number').columns\n",
    "\n",
    "# Replace negative values with NaN only in numeric columns\n",
    "df[numeric_cols] = df[numeric_cols].mask(df[numeric_cols] < 0, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Curated 4 meaningful feature sets including \n",
    "* Basic \n",
    "* Demographic heavy feature set \n",
    "* Support Services heavy feature set \n",
    "* All features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = {\n",
    "    'basic': student_teacher_ratio + \n",
    "              student_count +\n",
    "              staff_count,\n",
    "    \n",
    "    'demographics': \n",
    "        race_ethnicity_percent + \n",
    "        economically_disadvantaged +\n",
    "        language_education_percent +\n",
    "        special_populations_percent \n",
    "    ,\n",
    "    \n",
    "    'support_services': \n",
    "        special_ed_504 + \n",
    "        gifted_students +\n",
    "        language_education_percent +\n",
    "        special_populations_percent\n",
    "    ,\n",
    "    \n",
    "    'all_features': \n",
    "        student_teacher_ratio + \n",
    "        student_count +\n",
    "        staff_count +\n",
    "        race_ethnicity_percent +\n",
    "        economically_disadvantaged +\n",
    "        special_ed_504 +\n",
    "        language_education_percent +\n",
    "        special_populations_percent +\n",
    "        gifted_students\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Select 30 anchor districts.  \n",
    "Anchor districts are determined using proportional stratified sampling across the entire 2023 dataset. Stratification is a tool that tries to take a representative sample of a whole df based on specified columns. Stratification works because it keeps the sample small enough to compute, but diverse enough to trust your results\n",
    "   \n",
    "Districts are stratified based on\n",
    "* TEA Description: 8 columns outline what type of area district is in (Suburban, Urban, etc)\n",
    "* Region: 1-20 major state/region groupings determined by the TEA (San Antonio, Houston, etc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmath\\AppData\\Local\\Temp\\ipykernel_25444\\1514667669.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  anchor_districts = grouped.apply(lambda x: x.sample(1, random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Strip quotes and whitespace from REGION column if needed\n",
    "df['REGION'] = df['REGION'].str.strip().str.replace(\"'\", \"\")\n",
    "\n",
    "# Group by REGION and TEA Description, then sample 1 from each group\n",
    "grouped = df.groupby(['REGION', 'TEA Description'])\n",
    "\n",
    "# Sample 1 district from each unique group (if enough data exists)\n",
    "anchor_districts = grouped.apply(lambda x: x.sample(1, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "# Optional: Limit to 30 districts for feasibility\n",
    "anchor_df = anchor_districts.sample(n=30, random_state=42) if len(anchor_districts) > 30 else anchor_districts\n",
    "\n",
    "# Get district IDs\n",
    "anchor_ids = anchor_df['DISTRICT_id'].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Loop over distance metrics + feature sets \n",
    "* Iteratue over each feature set (step 1)\n",
    "* For each feature set, try each distance metric \n",
    "* For each combo, run find_nearest_districts() on every anchor district \n",
    "* Collect the neighbor district id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anchor_id</th>\n",
       "      <th>feature_set</th>\n",
       "      <th>distance_metric</th>\n",
       "      <th>neighbor_ids</th>\n",
       "      <th>neighbor_distname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>233901</td>\n",
       "      <td>basic</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>[233901, 15911, 101924, 227913, 159901]</td>\n",
       "      <td>[SAN FELIPE-DEL RIO CISD, EAST CENTRAL ISD, SH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13901</td>\n",
       "      <td>basic</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>[13901, 146906, 84908, 187907, 71904]</td>\n",
       "      <td>[BEEVILLE ISD, LIBERTY ISD, HITCHCOCK ISD, LIV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34905</td>\n",
       "      <td>basic</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>[34905, 127901, 157901, 183901, 34907]</td>\n",
       "      <td>[LINDEN-KILDARE CISD, ANSON ISD, MASON ISD, BE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>227901</td>\n",
       "      <td>basic</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>[227901, 170902, 79907, 220905, 101902]</td>\n",
       "      <td>[AUSTIN ISD, CONROE ISD, FORT BEND ISD, FORT W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>158901</td>\n",
       "      <td>basic</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>[158901, 15909, 247903, 161906, 247901]</td>\n",
       "      <td>[BAY CITY ISD, SOMERSET ISD, LA VERNIA ISD, LA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>94902</td>\n",
       "      <td>all_features</td>\n",
       "      <td>cosine</td>\n",
       "      <td>[94902, 46902, 20908, 43907, 199901]</td>\n",
       "      <td>[SCHERTZ-CIBOLO-U CITY ISD, COMAL ISD, PEARLAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>15907</td>\n",
       "      <td>all_features</td>\n",
       "      <td>cosine</td>\n",
       "      <td>[15907, 31901, 101911, 101903, 240903]</td>\n",
       "      <td>[SAN ANTONIO ISD, BROWNSVILLE ISD, GOOSE CREEK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>123910</td>\n",
       "      <td>all_features</td>\n",
       "      <td>cosine</td>\n",
       "      <td>[123910, 57907, 212905, 246906, 57910]</td>\n",
       "      <td>[BEAUMONT ISD, DUNCANVILLE ISD, TYLER ISD, HUT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>39902</td>\n",
       "      <td>all_features</td>\n",
       "      <td>cosine</td>\n",
       "      <td>[39902, 102906, 221904, 161918, 234903]</td>\n",
       "      <td>[HENRIETTA ISD, ELYSIAN FIELDS ISD, MERKEL ISD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>15912</td>\n",
       "      <td>all_features</td>\n",
       "      <td>cosine</td>\n",
       "      <td>[15912, 108908, 233901, 31906, 14909]</td>\n",
       "      <td>[SOUTHWEST ISD, MISSION CISD, SAN FELIPE-DEL R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     anchor_id   feature_set distance_metric  \\\n",
       "0       233901         basic       euclidean   \n",
       "1        13901         basic       euclidean   \n",
       "2        34905         basic       euclidean   \n",
       "3       227901         basic       euclidean   \n",
       "4       158901         basic       euclidean   \n",
       "..         ...           ...             ...   \n",
       "475      94902  all_features          cosine   \n",
       "476      15907  all_features          cosine   \n",
       "477     123910  all_features          cosine   \n",
       "478      39902  all_features          cosine   \n",
       "479      15912  all_features          cosine   \n",
       "\n",
       "                                neighbor_ids  \\\n",
       "0    [233901, 15911, 101924, 227913, 159901]   \n",
       "1      [13901, 146906, 84908, 187907, 71904]   \n",
       "2     [34905, 127901, 157901, 183901, 34907]   \n",
       "3    [227901, 170902, 79907, 220905, 101902]   \n",
       "4    [158901, 15909, 247903, 161906, 247901]   \n",
       "..                                       ...   \n",
       "475     [94902, 46902, 20908, 43907, 199901]   \n",
       "476   [15907, 31901, 101911, 101903, 240903]   \n",
       "477   [123910, 57907, 212905, 246906, 57910]   \n",
       "478  [39902, 102906, 221904, 161918, 234903]   \n",
       "479    [15912, 108908, 233901, 31906, 14909]   \n",
       "\n",
       "                                     neighbor_distname  \n",
       "0    [SAN FELIPE-DEL RIO CISD, EAST CENTRAL ISD, SH...  \n",
       "1    [BEEVILLE ISD, LIBERTY ISD, HITCHCOCK ISD, LIV...  \n",
       "2    [LINDEN-KILDARE CISD, ANSON ISD, MASON ISD, BE...  \n",
       "3    [AUSTIN ISD, CONROE ISD, FORT BEND ISD, FORT W...  \n",
       "4    [BAY CITY ISD, SOMERSET ISD, LA VERNIA ISD, LA...  \n",
       "..                                                 ...  \n",
       "475  [SCHERTZ-CIBOLO-U CITY ISD, COMAL ISD, PEARLAN...  \n",
       "476  [SAN ANTONIO ISD, BROWNSVILLE ISD, GOOSE CREEK...  \n",
       "477  [BEAUMONT ISD, DUNCANVILLE ISD, TYLER ISD, HUT...  \n",
       "478  [HENRIETTA ISD, ELYSIAN FIELDS ISD, MERKEL ISD...  \n",
       "479  [SOUTHWEST ISD, MISSION CISD, SAN FELIPE-DEL R...  \n",
       "\n",
       "[480 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "distance_metrics = [\n",
    "    'euclidean',\n",
    "    'manhattan',\n",
    "    'mahalanobis',\n",
    "    'cosine']\n",
    "\n",
    "\n",
    "for feature_name, features in feature_sets.items(): # Gathering all 4 of the feature combinations \n",
    "    for metric in distance_metrics: # Getting all 4 different distance metrics \n",
    "        for anchor_id in anchor_ids: #Gett all 30 specific districts\n",
    "            try:\n",
    "                neighbors = find_nearest_districts(df, anchor_id, features, 5, metric, \"median\") #running the neighbors code given the parameters \n",
    "                # Saving results to easy to manipulate dataframe \n",
    "                results.append({\n",
    "                    'anchor_id': anchor_id,\n",
    "                    'feature_set': feature_name,\n",
    "                    'distance_metric': metric,\n",
    "                    'neighbor_ids': list(neighbors['DISTRICT_id']), \n",
    "                    'neighbor_distname': list(neighbors['DISTNAME'])\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Failed for anchor {anchor_id} with {metric} on {feature_name}: {e}\")\n",
    "\n",
    "neighbor_results = pd.DataFrame(results)\n",
    "neighbor_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4 Examine Variance of Standardized Features\n",
    "\n",
    "* Standardization: To make variance comparisons fair across features, we standardized all columns used in any feature set across the entire dataset using StandardScaler.\n",
    "\n",
    "* Intra-Group Variance Calculation: For each neighbor group, we computed the average variance across its selected features. This serves as a proxy for how “tight” or internally similar each group is.\n",
    "\n",
    "* Distance Metric Comparison: We grouped the results by distance metric and computed the average intra-group variance for each one. Lower variance indicates tighter neighbor clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance_metric\n",
      "euclidean      0.099982\n",
      "manhattan      0.118397\n",
      "mahalanobis    0.130806\n",
      "cosine         0.282296\n",
      "Name: intra_group_variance, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# 1. Standardize the full dataset\n",
    "# Get a union of all feature columns used across feature sets\n",
    "all_feature_columns = sorted(set(col for sublist in feature_sets.values() for col in sublist))\n",
    "\n",
    "# Make a copy to avoid changing the original\n",
    "df_scaled = df.copy()\n",
    "scaler = StandardScaler()\n",
    "df_scaled[all_feature_columns] = scaler.fit_transform(df[all_feature_columns])\n",
    "\n",
    "# 2. Compute intra-group variance for each neighbor set\n",
    "variances = []\n",
    "\n",
    "\n",
    "for _, row in neighbor_results.iterrows():\n",
    "    neighbor_ids = row['neighbor_ids']  # List of neighbors\n",
    "    feature_cols = feature_sets[row['feature_set']]  # Selected feature set\n",
    "\n",
    "    # Subset the scaled data for these neighbors and features\n",
    "    neighbor_df = df_scaled[df_scaled['DISTRICT_id'].isin(neighbor_ids)][feature_cols].dropna()\n",
    "\n",
    "    # Skip if too few rows remain\n",
    "    if neighbor_df.shape[0] < 2:\n",
    "        variances.append(np.nan)\n",
    "        continue\n",
    "\n",
    "    # Compute variance across features and average\n",
    "    avg_variance = np.var(neighbor_df, axis=0).mean()\n",
    "    variances.append(avg_variance)\n",
    "\n",
    "# 3. Store results\n",
    "neighbor_results['intra_group_variance'] = variances\n",
    "\n",
    "variance_metric_summary = neighbor_results.groupby('distance_metric')['intra_group_variance'].mean().sort_values()\n",
    "print(variance_metric_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeaway: Euclidean performs the best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
