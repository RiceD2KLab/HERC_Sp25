{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries and Functions\n",
    "We are using Selenium - in particular webdriver, By, and NoSuchElementException, time, and os. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_downloads(variables, year, directory, timeout = 200):\n",
    "    start_time = time.time()\n",
    "    expected_files = []\n",
    "\n",
    "    for var in variables:\n",
    "\n",
    "        if year < 2021:\n",
    "            expected_files.append(f\"DIST{var}.dat\" if var != \"REF\" else \"DREF.dat\")\n",
    "        else:\n",
    "            expected_files.append(f\"DIST{var}.csv\" if var != \"REF\" else \"DREF.csv\")\n",
    "\n",
    "    while time.time() - start_time < timeout:\n",
    "        downloaded_files = os.listdir(directory)\n",
    "        \n",
    "        if all(file in downloaded_files and not file.endswith(\".crdownload\") for file in expected_files):\n",
    "            print(f\"All downloads for {year} completed successfully.\")\n",
    "            print(\"\")\n",
    "            return True\n",
    "        print(\"Waiting for all files to download...\")\n",
    "        time.sleep(5)\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for TAPR Scraping\n",
    "This function takes two list inputs and a string:\n",
    "* years is a list of YYYY integers (ex. 2018)\n",
    "* variables is a list of strings where each string is a dataset available on TAPR (ex. PROF)\n",
    "The function saves all .csv or .dat files to your local directory in separate directories for each year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "def tapr_scraper(years, variables):\n",
    "    dir = os.getcwd()  # getting the current working directory to save the files to\n",
    "    print(dir)\n",
    "    for year in years:\n",
    "        # access TAPR for each year\n",
    "        dir_name = f\"raw_data{year}\" # name a directory to store the raw data for that particular year\n",
    "        os.makedirs(dir_name, exist_ok=True) # create the directory unless it already exists\n",
    "        chromeOptions = webdriver.ChromeOptions() #creating chrome options object\n",
    "        prefs = {\"download.default_directory\" : f\"{dir}/{dir_name}\"}\n",
    "        chromeOptions.add_experimental_option(\"prefs\", prefs)\n",
    "        driver = webdriver.Chrome(options=chromeOptions)  # all files that are downloaded in the driver will now download to your directory (instead of \"Downloads\" folder)\n",
    "        driver.get(f\"https://rptsvr1.tea.texas.gov/perfreport/tapr/{year}/download/DownloadData.html\")  # open the TAPR url, depending on the year\n",
    "        # select district\n",
    "        district_select = driver.find_element(By.XPATH, \"//input[@type='radio' and @name='sumlev' and @value='D']\")  # select district level data\n",
    "        district_select.click()  # click the button\n",
    "        cant_download = []\n",
    "        print(f\"Downloading Data for {year}\")\n",
    "        roots = [] # initializing an empty list to keep track of the variables \n",
    "        for var in variables:  # for each data set\n",
    "            print(f\"Checking for DIST{var} data...\")\n",
    "            file_patterns = [f\"DIST{var}.csv\", f\"DIST{var}.dat\", f\"D{var}.dat\", f\"D{var}.csv\"]\n",
    "            if any(os.path.isfile(f\"{dir}/{dir_name}/{file}\") for file in file_patterns):\n",
    "                print(f\"{var} already exists\")\n",
    "                cant_download.append(var)\n",
    "                continue\n",
    "            try:\n",
    "                select_data = driver.find_element(By.XPATH, f\"//input[@type='radio' and @name='setpick' and @value='{var}']\")\n",
    "                select_data.click()  # click the data button\n",
    "                download = driver.find_element(By.XPATH, \"//input[@type='submit' and @value='Continue']\")\n",
    "                download.click()  # download the data\n",
    "                print(f\"{var} downloaded for {year}\")\n",
    "            except NoSuchElementException:\n",
    "                print(f\"{var} not found for {year}\")  # in case it doesn't exist, such as PERF1 not existing in earlier data\n",
    "                cant_download.append(var)\n",
    "                continue\n",
    "        if already_saved_or_not_available != len(variables):\n",
    "            time.sleep(60) # wait for all files to download before quitting the driver\n",
    "        driver.quit() # quit driver for that year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manav: Altered TAPR Scraper Function \n",
    "Updates: \n",
    "* Specify if you want campus, district, region, or state level data\n",
    "* Did not have to manually download each file to the path\n",
    "* Created the folders properly\n",
    "* Added addiitonal Chrome preferences \n",
    "* Gets the master refrence file (column name keys) and attaches it to the yearly documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/biancaschutz/HERC_Sp25\n",
      "Downloading Data for 2018\n",
      "Checking for DISTPROF data...\n",
      "PROF downloaded for 2018\n",
      "Checking for DISTPERF1 data...\n",
      "PERF1 not found for 2018\n",
      "Checking for DISTGRAD data...\n",
      "GRAD downloaded for 2018\n",
      "Checking for DISTSTAAR1 data...\n",
      "STAAR1 downloaded for 2018\n",
      "Checking for DISTREF data...\n",
      "REF downloaded for 2018\n",
      "Checking for DISTPERF data...\n",
      "PERF downloaded for 2018\n",
      "All downloads for 2018 completed successfully.\n",
      "Downloading Data for 2019\n",
      "Checking for DISTPROF data...\n",
      "PROF downloaded for 2019\n",
      "Checking for DISTPERF1 data...\n",
      "PERF1 not found for 2019\n",
      "Checking for DISTGRAD data...\n",
      "GRAD downloaded for 2019\n",
      "Checking for DISTSTAAR1 data...\n",
      "STAAR1 downloaded for 2019\n",
      "Checking for DISTREF data...\n",
      "REF downloaded for 2019\n",
      "Checking for DISTPERF data...\n",
      "PERF downloaded for 2019\n",
      "All downloads for 2019 completed successfully.\n",
      "Downloading Data for 2020\n",
      "Checking for DISTPROF data...\n",
      "PROF downloaded for 2020\n",
      "Checking for DISTPERF1 data...\n",
      "PERF1 not found for 2020\n",
      "Checking for DISTGRAD data...\n",
      "GRAD downloaded for 2020\n",
      "Checking for DISTSTAAR1 data...\n",
      "STAAR1 downloaded for 2020\n",
      "Checking for DISTREF data...\n",
      "REF downloaded for 2020\n",
      "Checking for DISTPERF data...\n",
      "PERF downloaded for 2020\n",
      "All downloads for 2020 completed successfully.\n",
      "Downloading Data for 2021\n",
      "Checking for DISTPROF data...\n",
      "PROF downloaded for 2021\n",
      "Checking for DISTPERF1 data...\n",
      "PERF1 downloaded for 2021\n",
      "Checking for DISTGRAD data...\n",
      "GRAD downloaded for 2021\n",
      "Checking for DISTSTAAR1 data...\n",
      "STAAR1 downloaded for 2021\n",
      "Checking for DISTREF data...\n",
      "REF downloaded for 2021\n",
      "Checking for DISTPERF data...\n",
      "PERF not found for 2021\n",
      "All downloads for 2021 completed successfully.\n",
      "Downloading Data for 2022\n",
      "Checking for DISTPROF data...\n",
      "PROF downloaded for 2022\n",
      "Checking for DISTPERF1 data...\n",
      "PERF1 downloaded for 2022\n",
      "Checking for DISTGRAD data...\n",
      "GRAD downloaded for 2022\n",
      "Checking for DISTSTAAR1 data...\n",
      "STAAR1 downloaded for 2022\n",
      "Checking for DISTREF data...\n",
      "REF downloaded for 2022\n",
      "Checking for DISTPERF data...\n",
      "PERF not found for 2022\n",
      "All downloads for 2022 completed successfully.\n",
      "Downloading Data for 2023\n",
      "Checking for DISTPROF data...\n",
      "PROF downloaded for 2023\n",
      "Checking for DISTPERF1 data...\n",
      "PERF1 downloaded for 2023\n",
      "Checking for DISTGRAD data...\n",
      "GRAD downloaded for 2023\n",
      "Checking for DISTSTAAR1 data...\n",
      "STAAR1 downloaded for 2023\n",
      "Checking for DISTREF data...\n",
      "REF downloaded for 2023\n",
      "Checking for DISTPERF data...\n",
      "PERF not found for 2023\n",
      "All downloads for 2023 completed successfully.\n"
     ]
    }
   ],
   "source": [
    "def tapr_scraper2(years, variables, directory_path_name, level):\n",
    "    \"\"\"\n",
    "    Scrape TAPR data for specified years, variables, and level if data.\n",
    "    \n",
    "    Parameters:\n",
    "    years (list): List of years to scrape data for\n",
    "    variables (list): List of variable codes to download\n",
    "    directory_path_name (str): Base directory to save files\n",
    "    level (str): Administrative level to scrape. Options:\n",
    "        'C' for Campus\n",
    "        'D' for District\n",
    "        'R' for Region\n",
    "        'S' for State\n",
    "    \"\"\"\n",
    "    # Validation for level parameter\n",
    "    valid_levels = {\n",
    "        'C': 'Campus',\n",
    "        'D': 'District',\n",
    "        'R': 'Region',\n",
    "        'S': 'State'\n",
    "    }\n",
    "    \n",
    "    if level not in valid_levels:\n",
    "        raise ValueError(f\"Invalid level. Must be one of: {', '.join(valid_levels.keys())}\")\n",
    "    \n",
    "    # Create prefix for filenames based on level\n",
    "    file_prefix = {\n",
    "        'C': 'CAMP',\n",
    "        'D': 'DIST',\n",
    "        'R': 'REGN',\n",
    "        'S': 'STATE'\n",
    "    }[level]\n",
    "    \n",
    "    # Ensure the base directory exists\n",
    "    os.makedirs(directory_path_name, exist_ok=True)\n",
    "    \n",
    "    for year in years:\n",
    "        # Create full path for year directory\n",
    "        dir_name = f\"raw_data{year}\"\n",
    "        full_dir_path = os.path.join(directory_path_name, dir_name)\n",
    "        os.makedirs(full_dir_path, exist_ok=True)\n",
    "        \n",
    "        # Configure Chrome options\n",
    "        chrome_options = webdriver.ChromeOptions()\n",
    "        absolute_download_path = os.path.abspath(full_dir_path)\n",
    "        \n",
    "        # Add additional Chrome preferences to prevent download prompts\n",
    "        prefs = {\n",
    "            \"download.default_directory\": absolute_download_path,\n",
    "            \"download.prompt_for_download\": False,\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing.enabled\": True,\n",
    "            \"profile.default_content_settings.popups\": 0\n",
    "        }\n",
    "        chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "        \n",
    "        # Add additional Chrome arguments\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"--no-sandbox\")\n",
    "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        \n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "        driver.get(f\"https://rptsvr1.tea.texas.gov/perfreport/tapr/{year}/download/DownloadData.html\")\n",
    "        \n",
    "        # Select appropriate level\n",
    "        level_select = driver.find_element(By.XPATH, f\"//input[@type='radio' and @name='sumlev' and @value='{level}']\")\n",
    "        level_select.click()\n",
    "        \n",
    "        already_saved_or_not_available = 0\n",
    "        print(f\"Downloading {valid_levels[level]} Level Data for {year}\")\n",
    "        \n",
    "        for var in variables:\n",
    "            print(f\"Checking for {file_prefix}{var} data...\")\n",
    "            # Updated file patterns to include level prefix and year\n",
    "            file_patterns = [\n",
    "                f\"{file_prefix}{var}_{year}.csv\",\n",
    "                f\"{file_prefix}{var}_{year}.dat\",\n",
    "                f\"{var}_{year}.dat\",  # Some files might not include the prefix\n",
    "                f\"{var}_{year}.csv\"\n",
    "            ]\n",
    "            \n",
    "            if any(os.path.isfile(os.path.join(full_dir_path, file)) for file in file_patterns):\n",
    "                print(f\"{var}_{year} already exists\")\n",
    "                already_saved_or_not_available += 1\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                select_data = driver.find_element(By.XPATH, f\"//input[@type='radio' and @name='setpick' and @value='{var}']\")\n",
    "                select_data.click()\n",
    "                \n",
    "                # Add a small delay after clicking the radio button\n",
    "                time.sleep(1)\n",
    "                \n",
    "                download = driver.find_element(By.XPATH, \"//input[@type='submit' and @value='Continue']\")\n",
    "                download.click()\n",
    "                print(f\"Downloaded {var} for {year}\")\n",
    "                \n",
    "                # Add a delay to ensure the download starts\n",
    "                time.sleep(3)\n",
    "                \n",
    "                # Rename the downloaded file to include the year\n",
    "                # Wait for the download to complete\n",
    "                max_wait = 30\n",
    "                start_time = time.time()\n",
    "                while time.time() - start_time < max_wait:\n",
    "                    # Check for both .csv and .dat files\n",
    "                    for ext in ['.csv', '.dat']:\n",
    "                        old_patterns = [\n",
    "                            f\"{file_prefix}{var}{ext}\",\n",
    "                            f\"{var}{ext}\"  # Some files might not include the prefix\n",
    "                        ]\n",
    "                        \n",
    "                        for old_pattern in old_patterns:\n",
    "                            old_name = os.path.join(full_dir_path, old_pattern)\n",
    "                            if os.path.exists(old_name):\n",
    "                                new_name = os.path.join(full_dir_path, f\"{file_prefix}{var}_{year}{ext}\")\n",
    "                                os.rename(old_name, new_name)\n",
    "                                break\n",
    "                        \n",
    "                        # If we found and renamed a file, break the inner loop\n",
    "                        if 'new_name' in locals() and os.path.exists(new_name):\n",
    "                            break\n",
    "                    \n",
    "                    # If we found and renamed a file, break the outer loop\n",
    "                    if 'new_name' in locals() and os.path.exists(new_name):\n",
    "                        break\n",
    "                        \n",
    "                    time.sleep(1)\n",
    "                \n",
    "            except NoSuchElementException:\n",
    "                print(f\"{var} not found for {year}\")\n",
    "                already_saved_or_not_available += 1\n",
    "                continue\n",
    "        \n",
    "        if already_saved_or_not_available != len(variables):\n",
    "            # Wait for downloads to complete by checking file sizes\n",
    "            max_wait = 120  # Maximum wait time in seconds\n",
    "            start_time = time.time()\n",
    "            while time.time() - start_time < max_wait:\n",
    "                time.sleep(5)\n",
    "                # Check if any file in the directory is still being downloaded (ends with .crdownload)\n",
    "                if not any(f.endswith('.crdownload') for f in os.listdir(full_dir_path)):\n",
    "                    break\n",
    "                \n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Campus Level Data for 2022\n",
      "Checking for CAMPPROF data...\n",
      "Downloaded PROF for 2022\n",
      "Checking for CAMPGRAD data...\n",
      "GRAD_2022 already exists\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"C:\\\\Users\\\\mmath\\\\OneDrive\\\\Desktop\\\\Capstone\\\\raw_data\"\n",
    "\n",
    "tapr_scraper2(years = [2022],\n",
    "              variables = ['PROF', 'GRAD'],\n",
    "                directory_path_name = file_path,\n",
    "                level = 'C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIP CODE: \n",
    "Joining the reference files to all docuements\n",
    "Not functional as of now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_references(year, directory_path_name, level='D'):\n",
    "    \"\"\"\n",
    "    Downloads the master reference file and extracts column names for each dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    year (str): Year to get references for\n",
    "    directory_path_name (str): Directory to save and process files\n",
    "    level (str): Administrative level ('C' for Campus, 'D' for District, \n",
    "                 'R' for Region, 'S' for State)\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary with dataset names as keys and their column names as values\n",
    "    \"\"\"\n",
    "    # Validation for level parameter and mapping to full names\n",
    "    valid_levels = {\n",
    "        'C': 'campus',\n",
    "        'D': 'district',\n",
    "        'R': 'region',\n",
    "        'S': 'state'\n",
    "    }\n",
    "    \n",
    "    if level not in valid_levels:\n",
    "        raise ValueError(f\"Invalid level. Must be one of: {', '.join(valid_levels.keys())}\")\n",
    "    \n",
    "    # Setup Chrome options\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    absolute_download_path = os.path.abspath(directory_path_name)\n",
    "    \n",
    "    prefs = {\n",
    "        \"download.default_directory\": absolute_download_path,\n",
    "        \"download.prompt_for_download\": False,\n",
    "        \"download.directory_upgrade\": True,\n",
    "        \"safebrowsing.enabled\": True,\n",
    "        \"profile.default_content_settings.popups\": 0\n",
    "    }\n",
    "    chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    \n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    \n",
    "    try:\n",
    "        # Navigate to the download page\n",
    "        driver.get(f\"https://rptsvr1.tea.texas.gov/perfreport/tapr/{year}/download/DownloadData.html\")\n",
    "        \n",
    "        # First find and click the main reference file section\n",
    "        # Look for text that contains \"Master Reference (Excel format)\"\n",
    "        main_ref_link = driver.find_element(By.XPATH, \"//a[contains(text(), 'Master Reference')]\")\n",
    "        main_ref_link.click()\n",
    "        \n",
    "        # Wait for the level options to be available\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Now click the specific level link\n",
    "        level_name = valid_levels[level]\n",
    "        level_link = driver.find_element(By.XPATH, f\"//a[contains(translate(text(), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), '{level_name}')]\")\n",
    "        level_link.click()\n",
    "        \n",
    "        # Wait for download to complete\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # Find the downloaded file - now looking for level-specific naming\n",
    "        ref_file = None\n",
    "        max_wait = 30\n",
    "        start_time = time.time()\n",
    "        \n",
    "        while time.time() - start_time < max_wait:\n",
    "            for file in os.listdir(absolute_download_path):\n",
    "                if file.endswith('.xlsx') and level_name in file.lower():\n",
    "                    ref_file = os.path.join(absolute_download_path, file)\n",
    "                    break\n",
    "            if ref_file:\n",
    "                break\n",
    "            time.sleep(1)\n",
    "        \n",
    "        if not ref_file:\n",
    "            raise Exception(f\"Reference file for {level_name} not found after {max_wait} seconds\")\n",
    "        \n",
    "        print(f\"Found reference file: {os.path.basename(ref_file)}\")\n",
    "        \n",
    "        # Read the Excel file and extract column names from each sheet\n",
    "        column_refs = {}\n",
    "        excel_file = pd.ExcelFile(ref_file)\n",
    "        \n",
    "        level_prefix = valid_levels[level]\n",
    "        \n",
    "        for sheet_name in excel_file.sheet_names:\n",
    "            # Only process sheets that match the selected level\n",
    "            if not sheet_name.lower().startswith(level_prefix):\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Read the sheet\n",
    "                df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
    "                \n",
    "                # Store the column references\n",
    "                # Usually first column is field name and second is description\n",
    "                # But check the actual column names to be sure\n",
    "                field_col = next(col for col in df.columns if 'field' in col.lower())\n",
    "                desc_col = next(col for col in df.columns if 'description' in col.lower())\n",
    "                \n",
    "                column_refs[sheet_name] = df[[field_col, desc_col]].values.tolist()\n",
    "                print(f\"Processed reference sheet: {sheet_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not process sheet {sheet_name}: {e}\")\n",
    "        \n",
    "        # Optionally remove the reference file after processing\n",
    "        os.remove(ref_file)\n",
    "        \n",
    "        return column_refs\n",
    "        \n",
    "    finally:\n",
    "        driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
